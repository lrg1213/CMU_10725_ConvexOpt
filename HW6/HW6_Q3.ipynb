{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import time\n",
    "from math import exp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "X, y = make_classification(n_samples=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda z : 1 / (1 + np.exp(-z))\n",
    "logloss = lambda y_hat, y : np.sum(-y * np.log(y_hat) - (1 - y) * np.log(1 - y_hat)) / len(y_hat)\n",
    "predict = lambda X: sigmoid(np.dot(X, betas.T)) > .5\n",
    "predict_with_output = lambda X: (X > .5) * 1\n",
    "\n",
    "\n",
    "def gradient_descent(X, y, beta, lr):\n",
    "    y = y.reshape(-1, 1)\n",
    "    gradients = np.dot(X.T, sigmoid(np.dot(X, beta.T)) - y) / len(y)\n",
    "    new_betas = beta - lr * gradients.T\n",
    "\n",
    "    return new_betas\n",
    "\n",
    "def prepare_batches(X, y, batch_size):\n",
    "    X_batch_list = list()\n",
    "    y_batch_list = list()\n",
    "    \n",
    "    for i in range(len(y) // batch_size):\n",
    "        X_batch_list.append(X[i * batch_size : i * batch_size + batch_size, :])\n",
    "        y_batch_list.append(y[i * batch_size : i * batch_size + batch_size])\n",
    "    \n",
    "    if len(y) % batch_size > 0:\n",
    "        X_batch_list.append(X[len(y) // batch_size * batch_size:, :])\n",
    "        y_batch_list.append(y[len(y) // batch_size * batch_size:])\n",
    "\n",
    "    return X_batch_list, y_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = np.random.permutation(len(X))\n",
    "\n",
    "X, y = np.asarray(X).squeeze(), np.asarray(y)\n",
    "\n",
    "X = X[permutations, :]\n",
    "y = y[permutations]\n",
    "\n",
    "# To add beta 0\n",
    "# temp = np.ones((X.shape[0], X.shape[1] + 1))\n",
    "# temp[:, 1:] = X\n",
    "# X = temp\n",
    "\n",
    "len_test = len(X) // 5 \n",
    "len_train = len(X) - len_test\n",
    "X_test, y_test, X_train, y_train = X[:len_test, :], y[:len_test], X[len_test:, :], y[len_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X matrix is: (10000, 20)\n",
      "Shape of y matrix is: (10000,)\n",
      "Shape of X_test matrix is: (2000, 20)\n",
      "Shape of y_test matrix is: (2000,)\n",
      "Shape of X_train matrix is: (8000, 20)\n",
      "Shape of y_train matrix is: (8000,)\n",
      "Desired samples feature vector: [ 0.84863467 -0.28172691 -1.87974165  0.54493492 -0.12580948 -2.13868216\n",
      " -0.09025264 -0.14493826  2.45129072 -1.04818521 -0.71652779 -0.33294089\n",
      "  0.00610335  0.17149833  0.15327923  0.51216418 -0.14056954  0.93593331\n",
      "  1.18642914 -0.47014197]\n",
      "Desired samples ground truth: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X matrix is: \" + str(X.shape))\n",
    "print(\"Shape of y matrix is: \" + str(y.shape))\n",
    "print(\"Shape of X_test matrix is: \" + str(X_test.shape))\n",
    "print(\"Shape of y_test matrix is: \" + str(y_test.shape))\n",
    "print(\"Shape of X_train matrix is: \" + str(X_train.shape))\n",
    "print(\"Shape of y_train matrix is: \" + str(y_train.shape))\n",
    "\n",
    "print(\"Desired samples feature vector: \" + str(X[2]))\n",
    "print(\"Desired samples ground truth: \" + str(y[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(X_train,y_train,lr,max_iter,epi=1e-6,patience=2):\n",
    "    train_error_hist, test_error_hist, test_acc_hist = MBGD(X_train=X_train,\n",
    "                                                            y_train=y_train,\n",
    "                                                            lr=lr,\n",
    "                                                            batch_size=1,\n",
    "                                                            max_iter=max_iter,\n",
    "                                                            epi=epi,\n",
    "                                                            patience=patience)\n",
    "    return train_error_hist, test_error_hist, test_acc_hist\n",
    "\n",
    "def MBGD(X_train,y_train,lr,batch_size,max_iter,epi=1e-6,patience=2):\n",
    "    train_error_hist = list()\n",
    "    test_error_hist = list()\n",
    "    test_acc_hist = list()\n",
    "\n",
    "    betas = np.random.random(X.shape[1]).reshape(1, -1)\n",
    "    X_batch_list, y_batch_list = prepare_batches(X_train, y_train, batch_size)\n",
    "    n_batches = len(y_batch_list)\n",
    "\n",
    "    prev_average = 10000\n",
    "\n",
    "    patience_counter = 0\n",
    "    iteration_counter = 0 \n",
    "    while iteration_counter < max_iter:\n",
    "        for i in range(n_batches):\n",
    "            X_batch = X_batch_list[i]\n",
    "            y_batch = y_batch_list[i]\n",
    "\n",
    "            betas = gradient_descent(X_batch, y_batch, betas, lr)\n",
    "\n",
    "            y_hat = sigmoid(np.dot(X_batch, betas.T))\n",
    "            train_error_hist.append(logloss(y_hat, y_batch) / len(y_batch))\n",
    "\n",
    "            y_hat = sigmoid(np.dot(X_test, betas.T))\n",
    "            test_error_hist.append(logloss(y_hat, y_test) / len(y_test))\n",
    "            test_acc_hist.append(np.mean((predict_with_output(y_hat) == y_test.reshape(-1, 1)) * 1))\n",
    "\n",
    "            iteration_counter += 1\n",
    "\n",
    "        current_average = np.mean(train_error_hist[-n_batches:])\n",
    "\n",
    "        if np.abs(prev_average - current_average) < epi:\n",
    "            patience_counter += 1\n",
    "        else:\n",
    "            patience_counter = 0\n",
    "\n",
    "        prev_average = current_average\n",
    "\n",
    "        if patience_counter == patience:\n",
    "            break\n",
    "    return  train_error_hist, test_error_hist, test_acc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error_hist, test_error_hist, test_acc_hist = MBGD(X_train,y_train,lr=0.05,batch_size=256,max_iter=1000,epi=1e-6,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error_hist, test_error_hist, test_acc_hist = SGD(X_train,y_train,lr=0.05,max_iter=1000,epi=1e-6,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_error_hist)\n",
    "plt.plot(train_error_hist)\n",
    "plt.xlabel(\"#Iterations\")\n",
    "plt.ylabel(\"Total Loss\")\n",
    "plt.title(\"Loss vs Number of iterations\")\n",
    "plt.legend((\"Test error\", \"Train error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_acc_hist)\n",
    "plt.xlabel(\"#Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs Number of iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
